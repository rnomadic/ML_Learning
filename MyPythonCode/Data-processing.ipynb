{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Data Challenge\n",
    "[Download Data](https://www.kaggle.com/chrisbow/cleaning-data-with-python-challenge-day-1/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jyotirmoyroy/miniconda3/envs/face_generation/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (22,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"resources/Building_Permits.csv\")\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permit Number</th>\n",
       "      <th>Permit Type</th>\n",
       "      <th>Permit Type Definition</th>\n",
       "      <th>Permit Creation Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Street Number</th>\n",
       "      <th>Street Number Suffix</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Street Suffix</th>\n",
       "      <th>...</th>\n",
       "      <th>Existing Construction Type</th>\n",
       "      <th>Existing Construction Type Description</th>\n",
       "      <th>Proposed Construction Type</th>\n",
       "      <th>Proposed Construction Type Description</th>\n",
       "      <th>Site Permit</th>\n",
       "      <th>Supervisor District</th>\n",
       "      <th>Neighborhoods - Analysis Boundaries</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Location</th>\n",
       "      <th>Record ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40553</th>\n",
       "      <td>201403039652</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>03/03/2014</td>\n",
       "      <td>3732</td>\n",
       "      <td>008</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clementina</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>constr type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>South of Market</td>\n",
       "      <td>94103.0</td>\n",
       "      <td>(37.780460571778164, -122.40450626524974)</td>\n",
       "      <td>1334094491645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169731</th>\n",
       "      <td>201510159735</td>\n",
       "      <td>3</td>\n",
       "      <td>additions alterations or repairs</td>\n",
       "      <td>10/15/2015</td>\n",
       "      <td>2609</td>\n",
       "      <td>028</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buena Vista</td>\n",
       "      <td>Tr</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Castro/Upper Market</td>\n",
       "      <td>94117.0</td>\n",
       "      <td>(37.76757916496494, -122.43793170417105)</td>\n",
       "      <td>1399356139170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19180</th>\n",
       "      <td>M409787</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>07/22/2013</td>\n",
       "      <td>4624</td>\n",
       "      <td>031</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>West Point</td>\n",
       "      <td>Rd</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Bayview Hunters Point</td>\n",
       "      <td>94124.0</td>\n",
       "      <td>(37.73524725436046, -122.38063828309745)</td>\n",
       "      <td>1311685491725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68047</th>\n",
       "      <td>201411191888</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>11/19/2014</td>\n",
       "      <td>0039</td>\n",
       "      <td>109</td>\n",
       "      <td>294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>North Beach</td>\n",
       "      <td>94133.0</td>\n",
       "      <td>(37.805257822817126, -122.40998545760392)</td>\n",
       "      <td>1362881288870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64238</th>\n",
       "      <td>M527228</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>10/14/2014</td>\n",
       "      <td>1251</td>\n",
       "      <td>002</td>\n",
       "      <td>707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cole</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Haight Ashbury</td>\n",
       "      <td>94117.0</td>\n",
       "      <td>(37.76836885973765, -122.45074431487859)</td>\n",
       "      <td>135886493776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Permit Number  Permit Type            Permit Type Definition  \\\n",
       "40553   201403039652            8            otc alterations permit   \n",
       "169731  201510159735            3  additions alterations or repairs   \n",
       "19180        M409787            8            otc alterations permit   \n",
       "68047   201411191888            8            otc alterations permit   \n",
       "64238        M527228            8            otc alterations permit   \n",
       "\n",
       "       Permit Creation Date Block  Lot  Street Number Street Number Suffix  \\\n",
       "40553            03/03/2014  3732  008            400                  NaN   \n",
       "169731           10/15/2015  2609  028             79                  NaN   \n",
       "19180            07/22/2013  4624  031            178                  NaN   \n",
       "68047            11/19/2014  0039  109            294                  NaN   \n",
       "64238            10/14/2014  1251  002            707                  NaN   \n",
       "\n",
       "        Street Name Street Suffix      ...        Existing Construction Type  \\\n",
       "40553    Clementina            St      ...                               NaN   \n",
       "169731  Buena Vista            Tr      ...                               5.0   \n",
       "19180    West Point            Rd      ...                               NaN   \n",
       "68047     Francisco            St      ...                               5.0   \n",
       "64238          Cole            St      ...                               NaN   \n",
       "\n",
       "       Existing Construction Type Description Proposed Construction Type  \\\n",
       "40553                                     NaN                        1.0   \n",
       "169731                         wood frame (5)                        5.0   \n",
       "19180                                     NaN                        NaN   \n",
       "68047                          wood frame (5)                        5.0   \n",
       "64238                                     NaN                        NaN   \n",
       "\n",
       "       Proposed Construction Type Description Site Permit Supervisor District  \\\n",
       "40553                           constr type 1         NaN                 6.0   \n",
       "169731                         wood frame (5)         NaN                 8.0   \n",
       "19180                                     NaN         NaN                10.0   \n",
       "68047                          wood frame (5)         NaN                 3.0   \n",
       "64238                                     NaN         NaN                 5.0   \n",
       "\n",
       "       Neighborhoods - Analysis Boundaries  Zipcode  \\\n",
       "40553                      South of Market  94103.0   \n",
       "169731                 Castro/Upper Market  94117.0   \n",
       "19180                Bayview Hunters Point  94124.0   \n",
       "68047                          North Beach  94133.0   \n",
       "64238                       Haight Ashbury  94117.0   \n",
       "\n",
       "                                         Location      Record ID  \n",
       "40553   (37.780460571778164, -122.40450626524974)  1334094491645  \n",
       "169731   (37.76757916496494, -122.43793170417105)  1399356139170  \n",
       "19180    (37.73524725436046, -122.38063828309745)  1311685491725  \n",
       "68047   (37.805257822817126, -122.40998545760392)  1362881288870  \n",
       "64238    (37.76836885973765, -122.45074431487859)   135886493776  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.head()\n",
    "#Look at a couple of rows from the sf_permits dataset. Do you notice any missing data?\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing value  26.26\n"
     ]
    }
   ],
   "source": [
    "#Find out what percent of the sf_permit dataset is missing\n",
    "## Calculate total number of cells in dataframe\n",
    "total_cell = np.product(df.shape)\n",
    "\n",
    "# Count number of missing values per column\n",
    "missing_count = df.isnull().sum()\n",
    "\n",
    "# Calculate total number of missing values\n",
    "total_missing = missing_count.sum() \n",
    "\n",
    "# Calculate percentage of missing values\n",
    "print(\"Percentage of missing value \", round(((total_missing/total_cell)*100), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the columns Street Number Suffix and Zipcode from the df datasets. Both of these contain missing values. Which, if either, of these are missing because they don't exist? Which, if either, are missing because they weren't recorded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Street Number Suffix    196684\n",
       "Zipcode                   1716\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_count[['Street Number Suffix', 'Zipcode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of missing zipcode 0.86\n",
      "Percent of missing Street number 98.89\n"
     ]
    }
   ],
   "source": [
    "#Looks like a lot more missing values for street number suffix than zipcode. Let's check out the percentages:\n",
    "\n",
    "print(\"Percent of missing zipcode\", round(((missing_count['Zipcode']/df.shape[0])*100),2))\n",
    "print(\"Percent of missing Street number\", round(((missing_count['Street Number Suffix']/df.shape[0])*100),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As every address has a Zipcode, it looks like the missing values for this column are due to the values not being recorded. For the Street Number Suffix column, it is likely very few properties will have a suffix to the number, I see a lot of 3s, 18s, 46s, but not nearly as many 36A or 18B, so it is likely that these are missing as they don't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permit Number</th>\n",
       "      <th>Permit Type</th>\n",
       "      <th>Permit Type Definition</th>\n",
       "      <th>Permit Creation Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Street Number</th>\n",
       "      <th>Street Number Suffix</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Street Suffix</th>\n",
       "      <th>...</th>\n",
       "      <th>Existing Construction Type</th>\n",
       "      <th>Existing Construction Type Description</th>\n",
       "      <th>Proposed Construction Type</th>\n",
       "      <th>Proposed Construction Type Description</th>\n",
       "      <th>Site Permit</th>\n",
       "      <th>Supervisor District</th>\n",
       "      <th>Neighborhoods - Analysis Boundaries</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Location</th>\n",
       "      <th>Record ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Permit Number, Permit Type, Permit Type Definition, Permit Creation Date, Block, Lot, Street Number, Street Number Suffix, Street Name, Street Suffix, Unit, Unit Suffix, Description, Current Status, Current Status Date, Filed Date, Issued Date, Completed Date, First Construction Document Date, Structural Notification, Number of Existing Stories, Number of Proposed Stories, Voluntary Soft-Story Retrofit, Fire Only Permit, Permit Expiration Date, Estimated Cost, Revised Cost, Existing Use, Existing Units, Proposed Use, Proposed Units, Plansets, TIDF Compliance, Existing Construction Type, Existing Construction Type Description, Proposed Construction Type, Proposed Construction Type Description, Site Permit, Supervisor District, Neighborhoods - Analysis Boundaries, Zipcode, Location, Record ID]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 43 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try removing all the rows from the sf_permits dataset that contain missing values. \n",
    "#How many are left?\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we drop all rows that contain a missing value, we greatly simplify our dataset. So simple, we can go for an early lunch. Every row contains at least one missing value (well, we know from our Street Number Suffix answer above that simply eliminating those gets rid of nearly 99% of our data), so we end up with a dataframe of column headers.\n",
    "\n",
    "**Now try removing all the columns with empty values. Now how much of your data is left?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permit Number</th>\n",
       "      <th>Permit Type</th>\n",
       "      <th>Permit Type Definition</th>\n",
       "      <th>Permit Creation Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Street Number</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Current Status</th>\n",
       "      <th>Current Status Date</th>\n",
       "      <th>Filed Date</th>\n",
       "      <th>Record ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201505065519</td>\n",
       "      <td>4</td>\n",
       "      <td>sign - erect</td>\n",
       "      <td>05/06/2015</td>\n",
       "      <td>0326</td>\n",
       "      <td>023</td>\n",
       "      <td>140</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>expired</td>\n",
       "      <td>12/21/2017</td>\n",
       "      <td>05/06/2015</td>\n",
       "      <td>1380611233945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201604195146</td>\n",
       "      <td>4</td>\n",
       "      <td>sign - erect</td>\n",
       "      <td>04/19/2016</td>\n",
       "      <td>0306</td>\n",
       "      <td>007</td>\n",
       "      <td>440</td>\n",
       "      <td>Geary</td>\n",
       "      <td>issued</td>\n",
       "      <td>08/03/2017</td>\n",
       "      <td>04/19/2016</td>\n",
       "      <td>1420164406718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201605278609</td>\n",
       "      <td>3</td>\n",
       "      <td>additions alterations or repairs</td>\n",
       "      <td>05/27/2016</td>\n",
       "      <td>0595</td>\n",
       "      <td>203</td>\n",
       "      <td>1647</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>withdrawn</td>\n",
       "      <td>09/26/2017</td>\n",
       "      <td>05/27/2016</td>\n",
       "      <td>1424856504716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201611072166</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>11/07/2016</td>\n",
       "      <td>0156</td>\n",
       "      <td>011</td>\n",
       "      <td>1230</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>complete</td>\n",
       "      <td>07/24/2017</td>\n",
       "      <td>11/07/2016</td>\n",
       "      <td>1443574295566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201611283529</td>\n",
       "      <td>6</td>\n",
       "      <td>demolitions</td>\n",
       "      <td>11/28/2016</td>\n",
       "      <td>0342</td>\n",
       "      <td>001</td>\n",
       "      <td>950</td>\n",
       "      <td>Market</td>\n",
       "      <td>issued</td>\n",
       "      <td>12/01/2017</td>\n",
       "      <td>11/28/2016</td>\n",
       "      <td>144548169992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Permit Number  Permit Type            Permit Type Definition  \\\n",
       "0  201505065519            4                      sign - erect   \n",
       "1  201604195146            4                      sign - erect   \n",
       "2  201605278609            3  additions alterations or repairs   \n",
       "3  201611072166            8            otc alterations permit   \n",
       "4  201611283529            6                       demolitions   \n",
       "\n",
       "  Permit Creation Date Block  Lot  Street Number Street Name Current Status  \\\n",
       "0           05/06/2015  0326  023            140       Ellis        expired   \n",
       "1           04/19/2016  0306  007            440       Geary         issued   \n",
       "2           05/27/2016  0595  203           1647     Pacific      withdrawn   \n",
       "3           11/07/2016  0156  011           1230     Pacific       complete   \n",
       "4           11/28/2016  0342  001            950      Market         issued   \n",
       "\n",
       "  Current Status Date  Filed Date      Record ID  \n",
       "0          12/21/2017  05/06/2015  1380611233945  \n",
       "1          08/03/2017  04/19/2016  1420164406718  \n",
       "2          09/26/2017  05/27/2016  1424856504716  \n",
       "3          07/24/2017  11/07/2016  1443574295566  \n",
       "4          12/01/2017  11/28/2016   144548169992  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_col = df.dropna(axis=1)\n",
    "clean_col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col in original data 43\n",
      "col in Nan droped 12\n"
     ]
    }
   ],
   "source": [
    "print(\"col in original data\", df.shape[1])\n",
    "print(\"col in Nan droped\", clean_col.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that gives us a clean set of values, but we've sacrificed a lot of variables in the process...\n",
    "\n",
    "**Now replacing all the NaN's in the df data with the one that comes directly after it and then [replace all the reamining na's with 0]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permit Number</th>\n",
       "      <th>Permit Type</th>\n",
       "      <th>Permit Type Definition</th>\n",
       "      <th>Permit Creation Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Street Number</th>\n",
       "      <th>Street Number Suffix</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Street Suffix</th>\n",
       "      <th>...</th>\n",
       "      <th>Existing Construction Type</th>\n",
       "      <th>Existing Construction Type Description</th>\n",
       "      <th>Proposed Construction Type</th>\n",
       "      <th>Proposed Construction Type Description</th>\n",
       "      <th>Site Permit</th>\n",
       "      <th>Supervisor District</th>\n",
       "      <th>Neighborhoods - Analysis Boundaries</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Location</th>\n",
       "      <th>Record ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201505065519</td>\n",
       "      <td>4</td>\n",
       "      <td>sign - erect</td>\n",
       "      <td>05/06/2015</td>\n",
       "      <td>0326</td>\n",
       "      <td>023</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>constr type 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>(37.785719256680785, -122.40852313194863)</td>\n",
       "      <td>1380611233945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201604195146</td>\n",
       "      <td>4</td>\n",
       "      <td>sign - erect</td>\n",
       "      <td>04/19/2016</td>\n",
       "      <td>0306</td>\n",
       "      <td>007</td>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>Geary</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>constr type 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>(37.78733980600732, -122.41063199757738)</td>\n",
       "      <td>1420164406718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201605278609</td>\n",
       "      <td>3</td>\n",
       "      <td>additions alterations or repairs</td>\n",
       "      <td>05/27/2016</td>\n",
       "      <td>0595</td>\n",
       "      <td>203</td>\n",
       "      <td>1647</td>\n",
       "      <td>0</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>Av</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>constr type 1</td>\n",
       "      <td>1</td>\n",
       "      <td>constr type 1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Russian Hill</td>\n",
       "      <td>94109.0</td>\n",
       "      <td>(37.7946573324287, -122.42232562979227)</td>\n",
       "      <td>1424856504716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201611072166</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>11/07/2016</td>\n",
       "      <td>0156</td>\n",
       "      <td>011</td>\n",
       "      <td>1230</td>\n",
       "      <td>0</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>Av</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>5</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Nob Hill</td>\n",
       "      <td>94109.0</td>\n",
       "      <td>(37.79595867909168, -122.41557405519474)</td>\n",
       "      <td>1443574295566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201611283529</td>\n",
       "      <td>6</td>\n",
       "      <td>demolitions</td>\n",
       "      <td>11/28/2016</td>\n",
       "      <td>0342</td>\n",
       "      <td>001</td>\n",
       "      <td>950</td>\n",
       "      <td>0</td>\n",
       "      <td>Market</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>constr type 3</td>\n",
       "      <td>5</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>(37.78315261897309, -122.40950883997789)</td>\n",
       "      <td>144548169992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Permit Number  Permit Type            Permit Type Definition  \\\n",
       "0  201505065519            4                      sign - erect   \n",
       "1  201604195146            4                      sign - erect   \n",
       "2  201605278609            3  additions alterations or repairs   \n",
       "3  201611072166            8            otc alterations permit   \n",
       "4  201611283529            6                       demolitions   \n",
       "\n",
       "  Permit Creation Date Block  Lot  Street Number Street Number Suffix  \\\n",
       "0           05/06/2015  0326  023            140                    0   \n",
       "1           04/19/2016  0306  007            440                    0   \n",
       "2           05/27/2016  0595  203           1647                    0   \n",
       "3           11/07/2016  0156  011           1230                    0   \n",
       "4           11/28/2016  0342  001            950                    0   \n",
       "\n",
       "  Street Name Street Suffix      ...       Existing Construction Type  \\\n",
       "0       Ellis            St      ...                              3.0   \n",
       "1       Geary            St      ...                              3.0   \n",
       "2     Pacific            Av      ...                              1.0   \n",
       "3     Pacific            Av      ...                              5.0   \n",
       "4      Market            St      ...                              3.0   \n",
       "\n",
       "  Existing Construction Type Description Proposed Construction Type  \\\n",
       "0                          constr type 3                          0   \n",
       "1                          constr type 3                          0   \n",
       "2                          constr type 1                          1   \n",
       "3                         wood frame (5)                          5   \n",
       "4                          constr type 3                          5   \n",
       "\n",
       "  Proposed Construction Type Description Site Permit Supervisor District  \\\n",
       "0                                      0           0                 3.0   \n",
       "1                                      0           0                 3.0   \n",
       "2                          constr type 1           0                 3.0   \n",
       "3                         wood frame (5)           0                 3.0   \n",
       "4                         wood frame (5)           0                 6.0   \n",
       "\n",
       "  Neighborhoods - Analysis Boundaries  Zipcode  \\\n",
       "0                          Tenderloin  94102.0   \n",
       "1                          Tenderloin  94102.0   \n",
       "2                        Russian Hill  94109.0   \n",
       "3                            Nob Hill  94109.0   \n",
       "4                          Tenderloin  94102.0   \n",
       "\n",
       "                                    Location      Record ID  \n",
       "0  (37.785719256680785, -122.40852313194863)  1380611233945  \n",
       "1   (37.78733980600732, -122.41063199757738)  1420164406718  \n",
       "2    (37.7946573324287, -122.42232562979227)  1424856504716  \n",
       "3   (37.79595867909168, -122.41557405519474)  1443574295566  \n",
       "4   (37.78315261897309, -122.40950883997789)   144548169992  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = df.fillna(method='ffill', axis=0).fillna(\"0\")\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas iloc vs ix vs loc explanation, how are they different?\n",
    "\n",
    "df.loc[:5] <br>\n",
    "df.ix[:5] <br>\n",
    "df.iloc[:5] <br>\n",
    "\n",
    "1. loc gets rows (or columns) with particular labels from the index.\n",
    "2. iloc gets rows (or columns) at particular positions in the index (so it only takes integers).\n",
    "3. ix usually tries to behave like loc but falls back to behaving like iloc if a label is not present in the index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49   NaN\n",
       "48   NaN\n",
       "47   NaN\n",
       "46   NaN\n",
       "45   NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "5    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(np.nan, index=[49,48,47,46,45, 1, 2, 3, 4, 5])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49   NaN\n",
       "48   NaN\n",
       "47   NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.iloc[:3] # slice the first three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49   NaN\n",
       "48   NaN\n",
       "47   NaN\n",
       "46   NaN\n",
       "45   NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " s.loc[:3] # slice up to and including label 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "nobel_winners = [\n",
    " {'category': 'Physics',\n",
    "  'name': 'Albert Einstein',\n",
    "  'nationality': 'Swiss',\n",
    "  'sex': 'male',\n",
    "  'year': 1921},\n",
    " {'category': 'Physics',\n",
    "  'name': 'Paul Dirac',\n",
    "  'nationality': 'British',\n",
    "  'sex': 'male',\n",
    "  'year': 1933},\n",
    " {'category': 'Chemistry',\n",
    "  'name': 'Marie Curie',\n",
    "  'nationality': 'Polish',\n",
    "  'sex': 'female',\n",
    "  'year': 1911}\n",
    "]\n",
    "\n",
    "\"\"\" For data-primitives such as strings, integers, floats etc.., Python dictionaries are easily\n",
    "saved (or dumped in the JSON vernacular) into JSON-files, using the json module.\n",
    "The dump method takes a Python container and a file-pointer, saving the former to the latter:\"\"\"\n",
    "\n",
    "with open('/Users/jyotirmoyroy/Joe/nobel_winner.json', 'w') as f:\n",
    "  json.dump(nobel_winners, f)\n",
    "\n",
    "\"\"\" Read the file with Normal I/O routine \"\"\"\n",
    "nobel_list1 = open('/Users/jyotirmoyroy/Joe/nobel_winner.json').read()\n",
    "\n",
    "print(nobel_list1)\n",
    "\n",
    "\"\"\" Or we can load the JSON file\"\"\"\n",
    "with open('/Users/jyotirmoyroy/Joe/nobel_winner.json') as f:\n",
    "  nobel_list =json.load(f)\n",
    "\n",
    "#print(nobel_list)\n",
    "\n",
    "\n",
    "\" Case 2: Need to create a histogram of domain from the list of email address in a file\"\n",
    "\"split the line on @ and count\"\n",
    "from collections import Counter\n",
    "def get_domain(email_address):\n",
    " return email_address.lower().split('@')[-1] #return the last part after the split\n",
    "\n",
    "with open('/Users/jyotirmoyroy/Joe/email_address.txt') as f:\n",
    " domain_counts = Counter(get_domain(line.strip())\n",
    "                         for line in f\n",
    "                         if '@' in line)\n",
    "\n",
    " print(domain_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing From embedding Project (URL Retrieve method)\n",
    "urllib.request.urlretrieve(url[, filename[, reporthook[, data]]])¶\n",
    "\n",
    "class tqdm(object):<br>\n",
    "  \"\"\"\n",
    "  Decorate an iterable object, returning an iterator which acts exactly\n",
    "  like the original iterable, but prints a dynamically updating\n",
    "  progressbar every time a value is requested.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, iterable=None, desc=None, total=None, leave=False,\n",
    "               file=sys.stderr, ncols=None, mininterval=0.1,\n",
    "               maxinterval=10.0, miniters=None, ascii=None,\n",
    "               disable=False, unit='it', unit_scale=False,\n",
    "               dynamic_ncols=False, smoothing=0.3, nested=False,\n",
    "               bar_format=None, initial=0, gui=False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm # for progress printing\n",
    "import zipfile\n",
    "\n",
    "dataset_folder_path = 'data'\n",
    "dataset_filename = 'text8.zip'\n",
    "dataset_name = 'Text8 Dataset'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "    \n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block)* block_size)\n",
    "        self.last_block = block_num\n",
    "        \n",
    "if not isfile(dataset_filename):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc=dataset_name) as pbar:\n",
    "        urlretrieve('http://mattmahoney.net/dc/text8.zip', dataset_filename, pbar.hook)\n",
    "        \n",
    "if not isdir(dataset_folder_path):\n",
    "    with zipfile.ZipFile(dataset_filename) as zip_ref:\n",
    "        zip_ref.extractall(dataset_folder_path)\n",
    "        \n",
    "with open('data/text8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded lookup table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "def create_lookup_table(words):\n",
    "    #first sort in reverse order(descending)\n",
    "    word_count = Counter(words)\n",
    "    sorted_words = sorted(word_count, key=word_count.get, reverse=True)\n",
    "    #create dictionary\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_words)} \n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Batches Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: A list where each item is a tuple of (batch of input, batch of target).\n",
    "\"\"\"\n",
    "\n",
    "def get_batches(int_txt, batch_size, seq_length):\n",
    "    \n",
    "    n_batches = int(len(int_txt) / (batch_size * seq_length))\n",
    "    \n",
    "    # Drop the last few characters to make only full batches\n",
    "    x_data = np.array(int_txt[: n_batches * batch_size * seq_length])\n",
    "    y_data = np.array(int_txt[1: n_batches * batch_size * seq_length + 1])\n",
    "    \n",
    "    #split into batches\n",
    "    x_batches = np.split(x_data.reshape(batch_size, -1), n_batches, 1)\n",
    "    y_batches = np.split(y_data.reshape(batch_size, -1), n_batches, 1)\n",
    "    \n",
    "    return list(zip(x_batches, y_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Sampling of words\n",
    "Words that show up often such as \"the\", \"of\", and \"for\" don't provide much context to the nearby words. If we discard some of them, we can remove some of the noise from our data and in return get faster training and better representations. This process is called subsampling.\n",
    "\n",
    "$$ P(w_i) = 1 - \\sqrt{\\frac{t}{f(w_i)}} $$\n",
    "\n",
    "where $t$ is a threshold parameter and $f(w_i)$ is the frequency of word $w_i$ in the total dataset.\n",
    "\n",
    "First, I'm creating dictionaries to covert words to integers and integers to words. The integers are assigned in descending frequency order, so the most frequent word (\"the\") is given the integer 0 and the next most frequent is 1 and so on. The words are converted to integers and stored in the list int_words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First create the dictionary\n",
    "vocab_to_int, int_to_vocab = create_lookup_tables(words)\n",
    "\n",
    "#Now create the list\n",
    "int_words = [vocab_to_int[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "threshold = 1e-5\n",
    "word_count = Counter(int_words)\n",
    "total_count = len(int_words)\n",
    "frew_word = {word: count/total_count for word, count in word_count.items()}\n",
    "p_drop = {word: 1 - np.sqrt(threshold/frew_word[word]) for word in word_count}\n",
    "\n",
    "trimed_word = [word for word in int_words if random.random() <(1 - p_word[word])] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ud120 project text (email data) processing\n",
    "### ud120-projects/tools/email_process.py\n",
    "\n",
    "processing steps: <br>\n",
    "            -- splits into training/testing sets (10% testing) <br>\n",
    "            -- vectorizes into tfidf matrix <br>\n",
    "            -- selects/keeps most helpful features <br>\n",
    "\n",
    "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
    "\n",
    "        4 objects are returned:\n",
    "            -- training/testing features\n",
    "            -- training/testing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "\n",
    "def preprocess(word_file=\"resources/word_data.pkl\", authors_file=\"resources/email_authors.pkl\"):\n",
    "    \n",
    "    authors_file_handler = open(authors_file, \"rb\")\n",
    "    authors = pickle.load(authors_file_handler)\n",
    "    authors_file_handler.close()\n",
    "        \n",
    "    word_file_handler = open(word_file, \"rb\")\n",
    "    word_data = pickle.load(word_file_handler)\n",
    "    word_file_handler.close()\n",
    "    \n",
    "    # test_size is the 10% of total data set\n",
    "    features_train, features_test, labels_train, labels_test = model_selection.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # text vectorization--go from strings to lists of numbers\n",
    "    \"\"\"\n",
    "    max_df : float in range [0.0, 1.0] or int, default=1.0\n",
    "    When building the vocabulary ignore terms that have a document frequency strictly higher \n",
    "    than the given threshold (corpus-specific stop words). \n",
    "    \"\"\"\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "    \n",
    "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "    features_test_transformed = vectorizer.fit(features_test)\n",
    "    \n",
    "    # feature selection, because text is super high dimensional and\n",
    "    # can be really computationally chewy as a result\n",
    "    selector = SelectPercentile(f_classif, percentile=10)\n",
    "    selector.fit(features_train_transformed, labels_train)\n",
    "    \n",
    "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
    "    features_test_transformed = selector.transform(features_test_transformed).toarray()\n",
    "    \n",
    "    \n",
    "        # info on the data\n",
    "    print (\"no. of Chris training emails:\", sum(labels_train))\n",
    "    print (\"no. of Sara training emails:\", len(labels_train)-sum(labels_train))\n",
    "    \n",
    "    return features_train_transformed, features_test_transformed, labels_train, labels_test\n",
    "\n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Read csv file and create dummies for categorical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit  gre   gpa  rank\n",
      "0      0  380  3.61     3\n",
      "1      1  660  3.67     3\n",
      "2      1  800  4.00     1\n",
      "3      1  640  3.19     4\n",
      "4      0  520  2.93     4\n",
      "Number of training samples is 360\n",
      "Number of testing samples is 40\n",
      "     admit       gre       gpa  rank_1  rank_2  rank_3  rank_4\n",
      "209      0 -0.066657  0.289305       0       1       0       0\n",
      "280      0  0.625884  1.445476       0       1       0       0\n",
      "33       1  1.837832  1.603135       0       0       1       0\n",
      "210      0  1.318426 -0.131120       0       0       0       1\n",
      "93       0 -0.066657 -1.208461       0       1       0       0\n",
      "84       1 -0.759199  0.552071       0       0       1       0\n",
      "329      0 -0.759199 -1.208461       0       0       0       1\n",
      "94       1  0.625884  0.131646       0       1       0       0\n",
      "266      0 -0.239793 -0.393886       0       0       0       1\n",
      "126      1  0.106478  0.394412       1       0       0       0\n",
      "     admit       gre       gpa  rank_1  rank_2  rank_3  rank_4\n",
      "20       0 -0.759199 -0.577822       0       0       1       0\n",
      "21       1  0.625884  0.630901       0       1       0       0\n",
      "48       0 -1.278605 -2.390908       0       0       0       1\n",
      "50       0  0.452749  1.235263       0       0       1       0\n",
      "54       0  0.625884 -0.131120       0       0       1       0\n",
      "58       0 -1.624876  0.683454       0       1       0       0\n",
      "71       0 -2.490553 -1.234737       0       0       0       1\n",
      "87       0  0.106478  0.236752       0       1       0       0\n",
      "99       0 -1.624876 -0.209950       0       0       1       0\n",
      "102      0 -1.798011 -0.157397       0       0       0       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "admissions = pd.read_csv(\"binary.csv\")\n",
    "\n",
    "print(admissions[:5])\n",
    "\n",
    "# Make dummy variables for rank\n",
    "data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
    "data = data.drop('rank', axis=1)\n",
    "\n",
    "#Standardize features\n",
    "for field in ['gre', 'gpa']:\n",
    "    mean, std = data[field].mean(), data[field].std()\n",
    "    data.loc[:, field] = (data[field] - mean)/std\n",
    "    \n",
    "#Split off random 10% of the data for testing\n",
    "np.random.seed(42)\n",
    "sample = np.random.choice(data.index, size=int(len(data)*0.9), replace=False)\n",
    "data, test_data = data.iloc[sample], data.drop(sample)\n",
    "\n",
    "\n",
    "print(\"Number of training samples is\", len(data))\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(data[:10])\n",
    "print(test_data[:10])\n",
    "\n",
    "# Split into features and targets\n",
    "features, targets = data.drop('admit', axis=1), data['admit']\n",
    "features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
